<html>
<head>
<title>Types</title>
<link rel="stylesheet" type="text/css" href="cssstyle.css"/>
<link rel="stylesheet" type="text/css" href="../Overview/cssstyle.css"/>
</head>
<body>
<header>
<div class="header1">
<h1 class="mainheader">About Computers</h1>
<img class="iconimage" src="../icon.png"/>
</div>
<div class="header2">
<ul>
<li><a href="../index.html">Overview</a></li>
<li><a href="../History/History.html">History</a></li>
<li><a href="" id="currenttab">Types</a></li>
<li><a href="../Future/future.html">Future</a></li>
<li><a href="../Feedback/feedback.html">Feedback</a></li>
</ul>
</div>
<div class="placeholder"></div>
</header>
<content>
<h2>Types</h2>
<hr/>
</br>
<p class="para1">Computers can be classified in a number of different ways, including:</p>
<div>
<h3>By architecture</h3>
<ul class="unorderedList">
<li>Analog computer</li>
<li>Digital computer</li>
<li>Hybrid computer</li>
<li>Harvard architecture</li>
<li>Von Neumann architecture</li>
<li>Reduced instruction set computer</li>
</ul>
<h3>By size and form-factor</h3>
<ul class="unorderedList">
<li>Mainframe computer</li>
<li>Supercomputer</li>
<li>Minicomputer</li>
<li>Microcomputer</li>
<li>Personal computer</li>
<li>Smartphone</li>
</ul>
</div>
</br>
<h2>By architecture</h2>
</br>
<h3>Analog computer</h3>
<p class="para1">
<img class="rightPic analogComputer" src="AnalogComputer.jpg"/>
An analog computer or analogue computer is a type of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically and by discrete values of both time and amplitude.
</br>
</br>
Analog computers can have a very wide range of complexity. Slide rules and nomograms are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.
</br>
</br>
Analog computers were widely used in scientific and industrial applications even after the advent of digital computers, because at the time they were typically much faster, but they started to become obsolete as early as the 1950s and 1960s, although remained in use in some specific applications, such as aircraft flight simulators, the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as aircraft flight simulators and synthetic aperture radar, remained the domain of analog computing (and hybrid computing) well into the 1980s, since digital computers were insufficient for the task.
</p>
<h3>Digital computer</h3>
<p class="para1">
<a href="../History/history.html#digitalComputers">Goto Digital Computer &#128279</a>
</p>
<div class="emptypara"></div>
<h3>Hybrid Computer</h3>
<p class="para1 para2">
<img class="rightPic hybridComputer"src="HybridComputer.jpg">
Hybrid computers are computers that exhibit features of analog computers and digital computers. The digital component normally serves as the controller and provides logical and numerical operations, while the analog component often serves as a solver of differential equations and other mathematically complex equations. The first desktop hybrid computing system was the Hycomp 250, released by Packard Bell in 1961. Another early example was the HYDAC 2400, an integrated hybrid computer released by EAI in 1963. In the 1980s, Marconi Space and Defense Systems Limited (under Peggy Hodges) developed their "Starglow Hybrid Computer", which consisted of three EAI 8812 analog computers linked to an EAI 8100 digital computer, the latter also being linked to an SEL 3200 digital computer. Late in the 20th century, hybrids dwindled with the increasing capabilities of digital computers including digital signal processors.
</br>
</br>
In general, analog computers are extraordinarily fast, since they are able to solve most mathematically complex equations at the rate at which a signal traverses the circuit, which is generally an appreciable fraction of the speed of light. On the other hand, the precision of analog computers is not good; they are limited to three, or at most, four digits of precision.
</br>
</br>
Digital computers can be built to take the solution of equations to almost unlimited precision, but quite slowly compared to analog computers. Generally, complex mathematical equations are approximated using iterative methods which take huge numbers of iterations, depending on how good the initial "guess" at the final value is and how much precision is desired. (This initial guess is known as the numerical "seed".) For many real-time operations in the 20th century, such digital calculations were too slow to be of much use (e.g., for very high frequency phased array radars or for weather calculations), but the precision of an analog computer is insufficient.
</br>
</br>
Hybrid computers can be used to obtain a very good but relatively imprecise 'seed' value, using an analog computer front-end, which is then fed into a digital computer iterative process to achieve the final desired degree of precision. With a three or four digit, highly accurate numerical seed, the total digital computation time to reach the desired precision is dramatically reduced, since many fewer iterations are required. One of the main technical problems to be overcome in hybrid computers is minimizing digital-computer noise in analog computing elements and grounding systems.
</br>
</br>
Consider that the nervous system in animals is a form of hybrid computer. Signals pass across the synapses from one nerve cell to the next as discrete (digital) packets of chemicals, which are then summed within the nerve cell in an analog fashion by building an electro-chemical potential until its threshold is reached, whereupon it discharges and sends out a series of digital packets to the next nerve cell. The advantages are at least threefold: noise within the system is minimized (and tends not to be additive), no common grounding system is required, and there is minimal degradation of the signal even if there are substantial differences in activity of the cells along a path (only the signal delays tend to vary). The individual nerve cells are analogous to analog computers; the synapses are analogous to digital computers.
</br>
</br>
Hybrid computers should be distinguished from hybrid systems. The latter may be no more than a digital computer equipped with an analog-to-digital converter at the input and/or a digital-to-analog converter at the output, to convert analog signals for ordinary digital signal processing, and conversely, e.g., for driving physical control systems, such as servomechanisms.
</p>
<h3>Harvard Architecture</h3>
<p class="para1">
<img class="rightPic havardArchitecture" src="HarvardArchitecture.svg">
The Harvard architecture is a computer architecture with separate storage and signal pathways for instructions and data. It contrasts with the von Neumann architecture, where program instructions and data share the same memory and pathways.
</br>
</br>
The term originated from the Harvard Mark I relay-based computer, which stored instructions on punched tape (24 bits wide) and data in electro-mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialize itself.
</br>
</br>
Modern processors appear to the user to be von Neumann machines, with the program code stored in the same main memory as the data. For performance reasons, internally and largely invisible to the user, most designs have separate processor caches for the instructions and data, with separate pathways into the processor for each. This is one form of what is known as the modified Harvard architecture.
</p>
<div class="emptypara"></div>
<h3>Reduced instruction set computer</h3>
<p class="para1">
<img class="rightPic risc" src="RISC.jpg">
A reduced instruction set computer, or RISC (/rÉªsk/), is a computer instruction set (AKA: the instruction set architecture (ISA)) which allows a computer's microprocessor to have fewer cycles per instruction (CPI) than a complex instruction set computer (CISC).
</br>
</br>
Various suggestions have been made regarding a precise definition of RISC, but the general concept is that such a computer has a small set of simple and general instructions, rather than a large set of complex and specialized instructions. The main distinguishing feature of RISC is that the instruction set is optimized for a highly regular instruction pipeline flow. Another common RISC trait is their load/store architecture, in which memory is accessed through specific instructions rather than as a part of most instructions.
</br>
</br>
Although a number of computers from the 1960s and 1970s have been identified as forerunners of RISCs, the modern concept dates to the 1980s. In particular, two projects at Stanford University and the University of California, Berkeley are most associated with the popularization of this concept. Stanford's MIPS would go on to be commercialized as the successful MIPS architecture, while Berkeley's RISC gave its name to the entire concept and was commercialized as the SPARC. Another success from this era was IBM's effort that eventually led to the IBM POWER instruction set architecture, PowerPC, and Power ISA. As these projects matured, a wide variety of similar designs flourished in the late 1980s and especially the early 1990s, representing a major force in the Unix workstation market as well as for embedded processors in laser printers, routers and similar products.
</br>
</br>
The many varieties of RISC designs include ARC, Alpha, Am29000, ARM, Atmel AVR, Blackfin, i860, i960, M88000, MIPS, PA-RISC, Power ISA (including PowerPC), RISC-V, SuperH, and SPARC. The use of ARM architecture processors in smartphones and tablet computers such as the iPad and Android devices provided a wide user base for RISC-based systems. RISC processors are also used in supercomputers such as Summit, which, as of January 2020, is the world's fastest supercomputer as ranked by the TOP500 project.
</p>
<h2>By size and form-factor</h2>
</br>
<h3>Mainframe computer</h3>
<p class="para1">
<img class="leftPic havardArchitecture" src="MainFrameComputer.jpg"/>
Mainframe computers or mainframes (colloquially referred to as "big iron") are computers used primarily by large organizations for critical applications; bulk data processing, such as census, industry and consumer statistics, enterprise resource planning; and transaction processing. They are larger and have more processing power than some other classes of computers: minicomputers, servers, workstations, and personal computers.
</br>
</br>
The term originally referred to the large cabinets called "main frames" that housed the central processing unit and main memory of early computers. Later, the term was used to distinguish high-end commercial machines from less powerful units. Most large-scale computer system architectures were established in the 1960s, but continue to evolve. Mainframe computers are often used as servers.
</p>
<div class="emptypara"></div>
<div class="emptypara"></div>
<h3>Supercomputer</h3>
<p class="para1">
<img class="rightPic havardArchitecture" src="SuperComputer.jpg"/>
A supercomputer is a computer with a high level of performance as compared to a general-purpose computer. The performance of a supercomputer is commonly measured in floating-point operations per second (FLOPS) instead of million instructions per second (MIPS). Since 2017, there are supercomputers which can perform over a hundred quadrillion FLOPS (petaFLOPS). Since November 2017, all of the world's fastest 500 supercomputers run Linux-based operating systems. Additional research is being conducted in China, the United States, the European Union, Taiwan and Japan to build even faster, more powerful and technologically superior exascale supercomputers.
</br>
</br>
Supercomputers play an important role in the field of computational science, and are used for a wide range of computationally intensive tasks in various fields, including quantum mechanics, weather forecasting, climate research, oil and gas exploration, molecular modeling (computing the structures and properties of chemical compounds, biological macromolecules, polymers, and crystals), and physical simulations (such as simulations of the early moments of the universe, airplane and spacecraft aerodynamics, the detonation of nuclear weapons, and nuclear fusion). Throughout their history, they have been essential in the field of cryptanalysis.
</br>
</br>
Supercomputers were introduced in the 1960s, and for several decades the fastest were made by Seymour Cray at Control Data Corporation (CDC), Cray Research and subsequent companies bearing his name or monogram. The first such machines were highly tuned conventional designs that ran faster than their more general-purpose contemporaries. Through the 1960s, they began to add increasing amounts of parallelism with one to four processors being typical. From the 1970s, vector processors operating on large arrays of data came to dominate. A notable example is the highly successful Cray-1 of 1976. Vector computers remained the dominant design into the 1990s. From then until today, massively parallel supercomputers with tens of thousands of off-the-shelf processors became the norm.
</br>
</br>
The US has long been the leader in the supercomputer field, first through Cray's almost uninterrupted dominance of the field, and later through a variety of technology companies. Japan made major strides in the field in the 1980s and 90s, but since then China has become increasingly active in the field. As of November 2018, the fastest supercomputer on the TOP500 supercomputer list is the Summit, in the United States, with a LINPACK benchmark score of 143.5 PFLOPS, followed by, Sierra, by around 48.860 PFLOPS. The US has five of the top 10 and China has two. In June 2018, all supercomputers on the list combined broke the 1 exaFLOPS mark.
</p>
<h3>Minicomputer</h3>
<p class="para1">
<img class="rightPic analogComputer" src="MiniComputer.jpg"/>
A minicomputer, or colloquially mini, is a class of smaller computers that was developed in the mid-1960's and sold for much less than mainframe and mid-size computers from IBM and its direct competitors. In a 1970 survey, The New York Times suggested a consensus definition of a minicomputer as a machine costing less than US$25,000 (equivalent to $165,000 in 2019), with an input-output device such as a teleprinter and at least four thousand words of memory, that is capable of running programs in a higher level language, such as Fortran or BASIC. The class formed a distinct group with its own software architectures and operating systems. Minis were designed for control, instrumentation, human interaction, and communication switching as distinct from calculation and record keeping. Many were sold indirectly to original equipment manufacturers (OEMs) for final end use application. During the two decade lifetime of the minicomputer class (1965â1985), almost 100 companies formed and only a half dozen remained.
</br>
</br>
When single-chip CPU microprocessors appeared, beginning with the Intel 4004 in 1971, the term "minicomputer" came to mean a machine that lies in the middle range of the computing spectrum, in between the smallest mainframe computers and the microcomputers. The term "minicomputer" is little used today; the contemporary term for this class of system is "midrange computer", such as the higher-end SPARC, Power ISA and Itanium-based systems from Oracle, IBM and Hewlett-Packard.
</p>
<div class="emptypara"></div>
<h3>Microcomputer</h3>
<p class="para1">
<img class="leftPic microComputer" src="MicroComputer.jpg"/>
A microcomputer is a small, relatively inexpensive computer with a microprocessor as its central processing unit (CPU). It includes a microprocessor, memory and minimal input/output (I/O) circuitry mounted on a single printed circuit board(PCB). Microcomputers became popular in the 1970s and 1980s with the advent of increasingly powerful microprocessors. The predecessors to these computers, mainframes and minicomputers, were comparatively much larger and more expensive (though indeed present-day mainframes such as the IBM System z machines use one or more custom microprocessors as their CPUs). Many microcomputers (when equipped with a keyboard and screen for input and output) are also personal computers (in the generic sense).
</br>
The abbreviation micro was common during the 1970s and 1980s, but has now fallen out of common usage.
</p>
<div class="emptypara"></div>
<h3>Personal computer</h3>
<p class="para1">
<img class="rightPic risc" src="PC.jpg"/>
A personal computer (PC) is a multi-purpose computer whose size, capabilities, and price make it feasible for individual use. Personal computers are intended to be operated directly by an end user, rather than by a computer expert or technician. Unlike large costly minicomputer and mainframes, time-sharing by many people at the same time is not used with personal computers.
</br>
</br>
Institutional or corporate computer owners in the 1960s had to write their own programs to do any useful work with the machines. While personal computer users may develop their own applications, usually these systems run commercial software, free-of-charge software ("freeware") or free and open-source software, which is provided in ready-to-run form. Software for personal computers is typically developed and distributed independently from the hardware or operating system manufacturers. Many personal computer users no longer need to write their own programs to make any use of a personal computer, although end-user programming is still feasible. This contrasts with mobile systems, where software is often only available through a manufacturer-supported channel, and end-user program development may be discouraged by lack of support by the manufacturer.
</br>
</br>
Since the early 1990s, Microsoft operating systems and Intel hardware have dominated much of the personal computer market, first with MS-DOS and then with Microsoft Windows. Alternatives to Microsoft's Windows operating systems occupy a minority share of the industry. These include Apple's macOS and free and open-source Unix-like operating systems.
</br>
</br>
The advent of personal computers and the concurrent Digital Revolution have significantly affected the lives of people in all countries.
</p>
<h3>Smartphone</h3>
<p class="para1">
<img class="rightPic havardArchitecture" src="Smartphone.jpg"/>
Smartphones are a class of mobile phones and of multi-purpose mobile computing devices. They are distinguished from feature phones by their stronger hardware capabilities and extensive mobile operating systems, which facilitate wider software, internet (including web browsing over mobile broadband), and multimedia functionality (including music, video, cameras, and gaming), alongside core phone functions such as voice calls and text messaging. Smartphones typically contain a number of metalâoxideâsemiconductor (MOS) integrated circuit (IC) chips, include various sensors that can be leveraged by their software (such as a magnetometer, proximity sensors, barometer, gyroscope, or accelerometer), and support wireless communications protocols (such as Bluetooth, Wi-Fi, or satellite navigation).
</br>
</br>
Early smartphones were marketed primarily towards the enterprise market, attempting to bridge the functionality of standalone personal digital assistant (PDA) devices with support for cellular telephony, but were limited by their bulky form, short battery life, slow analog cellular networks, and the immaturity of wireless data services. These issues were eventually resolved with the exponential scaling and miniaturization of MOS transistors down to sub-micron levels (Moore's law), the improved lithium-ion battery, faster digital mobile data networks (Edholm's law), and more mature software platforms that allowed mobile device ecosystems to develop independently of data providers.
</br>
</br>
In the 2000s, NTT DoCoMo's i-mode platform, BlackBerry, Nokia's Symbian platform, and Windows Mobile began to gain market traction, with models often featuring QWERTY keyboards or resistive touchscreen input, and emphasizing access to push email and wireless internet. Since the unveiling of the iPhone in 2007, the majority of smartphones have featured thin, slate-like form factors, with large, capacitive screens with support for multi-touch gestures rather than physical keyboards, and offer the ability for users to download or purchase additional applications from a centralized store, and use cloud storage and synchronization, virtual assistants, as well as mobile payment services.
</br>
</br>
Improved hardware and faster wireless communication (due to standards such as LTE) have bolstered the growth of the smartphone industry. In the third quarter of 2012, one billion smartphones were in use worldwide. Global smartphone sales surpassed the sales figures for feature phones in early 2013.
</p>
</content>
<footer>
<div class="footer"><div class="footerNote">Document and Image Sources:
<ul style="padding-left:50px">
<li>https://en.wikipedia.org/wiki/Computer</li>
<li>https://peda.net/kenya/ass/subjects2/computer-studies/form-1/the-computer-system</li>
<li>Google</li>
</ul>
</div>
</footer>
</body>
</html>